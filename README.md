# ğŸš Bardacle

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)

**A metacognitive layer for AI agents.**

Bardacle watches your agent's session transcript and maintains a real-time "session state" summary. When context gets compacted or sessions restart, your agent can read this state to pick up exactly where it left off.

Think of it as **short-term memory that survives context loss**.

<p align="center">
  <img src="assets/logo.svg" alt="Bardacle Logo" width="150">
</p>

---

## âœ¨ Features

- **ğŸ§  Metacognitive Awareness** â€” Tracks what the agent is working on, not just conversation history
- **ğŸ”§ Tool Awareness** â€” Summarizes tool calls (`[exec] deploy.sh â†’ âœ“`) so the agent knows what happened
- **ğŸ  Local-First** â€” Uses local LLMs (LM Studio, Ollama) by default, keeping your data private
- **â˜ï¸ Cloud Fallback** â€” Falls back to Groq â†’ OpenAI when local fails
- **âš¡ Rate Limit Detection** â€” Automatically skips rate-limited providers
- **ğŸ“Š Incremental Updates** â€” Updates existing state instead of regenerating from scratch
- **ğŸ“ˆ Metrics Logging** â€” Tracks latency, model used, messages analyzed
- **ğŸ³ Docker Ready** â€” Run containerized with one command

---

## ğŸš€ Quick Start

### Install

```bash
# Clone the repository
git clone https://github.com/StellarSk8board/bardacle.git
cd bardacle

# Install
pip install -e .
```

### Configure

```bash
# Copy example config
cp config.example.yaml config.yaml

# Edit with your paths
nano config.yaml
```

Minimal config:
```yaml
transcripts:
  dir: "~/.your-agent/sessions"
  pattern: "*.jsonl"

output:
  state_file: "~/.your-agent/session-state.md"
```

### Run

```bash
# Test the setup
bardacle test

# Start the daemon
bardacle start

# Check status
bardacle status
```

### Integrate with Your Agent

Add to your agent's instructions:
```
"At the start of each response, read session-state.md for current context."
```

That's it! Your agent now has persistent short-term memory.

---

## ğŸ“– How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent Session                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ User: Help me deploy my app                             â”‚â”‚
â”‚  â”‚ Agent: Sure! Let me check the config... [exec] cat...   â”‚â”‚
â”‚  â”‚ Agent: Found an issue. Fixing now... [Write] config.yml â”‚â”‚
â”‚  â”‚ User: Great, now run the tests                          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                            â”‚                                 â”‚
â”‚                            â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  ğŸ“ Transcript (JSONL)                                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš Bardacle                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Watch          â”‚â†’ â”‚ Summarize      â”‚â†’ â”‚ Extract State  â”‚ â”‚
â”‚  â”‚ Transcript     â”‚  â”‚ Tool Calls     â”‚  â”‚ via LLM        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                    â”‚         â”‚
â”‚                                                    â–¼         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  session-state.md                                       â”‚â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚â”‚
â”‚  â”‚  Current Goal: Deploy the application                   â”‚â”‚
â”‚  â”‚  Active Tasks: Run tests (in progress)                  â”‚â”‚
â”‚  â”‚  Recent: Fixed config issue                             â”‚â”‚
â”‚  â”‚  Next: Execute test suite                               â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent reads session-state.md â†’ Knows what it was doing     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Configuration

### Environment Variables

```bash
# Cloud API keys (optional but recommended for fallback)
export GROQ_API_KEY="gsk_..."
export OPENAI_API_KEY="sk-..."

# Override config paths
export BARDACLE_TRANSCRIPTS_DIR="/path/to/sessions"
export BARDACLE_STATE_FILE="/path/to/session-state.md"
export BARDACLE_LOCAL_URL="http://localhost:1234"
```

### Full Config Example

```yaml
inference:
  local_url: "http://localhost:1234"
  local_model_fast: "qwen2.5-coder-7b-instruct"
  local_model_smart: "qwen3-coder-30b-a3b-instruct"
  local_timeout: 15
  groq_model: "llama-3.1-8b-instant"
  openai_model: "gpt-4o-mini"
  cloud_timeout: 30

transcripts:
  dir: "~/.agent/sessions"
  pattern: "*.jsonl"

processing:
  max_messages: 100
  max_message_chars: 500
  debounce_seconds: 5
  force_update_interval: 120
  poll_interval: 2

output:
  state_file: "~/.agent/session-state.md"
  log_file: "~/.bardacle/bardacle.log"
  metrics_file: "~/.bardacle/metrics.jsonl"
```

---

## ğŸ“Š Fallback Chain

Bardacle tries inference in this order:

```
1. Local LLM (15s timeout)     â”€â”€â”€ Fast, free, private
         â”‚
         â–¼ (timeout/error)
2. Groq Cloud                  â”€â”€â”€ Fast, free tier
         â”‚
         â–¼ (rate limit/error)
3. OpenAI                      â”€â”€â”€ Reliable fallback
         â”‚
         â–¼ (error)
4. Local Smart Model           â”€â”€â”€ Last resort
```

Rate limit detection: When Groq returns 429, Bardacle skips it for 60 seconds.

---

## ğŸ³ Docker

### Quick Start

```bash
docker run -d \
  -e GROQ_API_KEY="your-key" \
  -v /path/to/transcripts:/data/transcripts:ro \
  -v /path/to/output:/data/output \
  ghcr.io/stellarsk8board/bardacle:latest
```

### With Docker Compose

```yaml
version: '3.8'
services:
  bardacle:
    image: ghcr.io/stellarsk8board/bardacle:latest
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
      - BARDACLE_LOCAL_URL=http://host.docker.internal:1234
    volumes:
      - ./transcripts:/data/transcripts:ro
      - ./output:/data/output
    extra_hosts:
      - "host.docker.internal:host-gateway"
```

---

## ğŸ“„ Session State Format

Bardacle generates a markdown file:

```markdown
# Session State

*Auto-generated at 2026-02-07 21:30:15*
*Model: groq | Latency: 0.4s | Messages: 50*

---

## Current Goal
Deploy the web application to production

## Active Tasks
- [done] Fix configuration issue
- [in progress] Run test suite
- [pending] Deploy to production

## Recent Decisions
- Using Docker for deployment
- PostgreSQL over MySQL for the database

## Blockers
None

## Next Steps
1. Wait for tests to complete
2. Review test results
3. Deploy if all tests pass

## Key Context
- App: FastAPI web service
- Environment: Production
- Deployment target: AWS ECS
```

---

## ğŸ“š Documentation

- **[Installation Guide](docs/installation.md)** â€” Detailed setup instructions
- **[Quickstart](docs/quickstart.md)** â€” Get running in 5 minutes
- **[Transcript Adapters](docs/adapters.md)** â€” Support different formats
- **[Troubleshooting](docs/troubleshooting.md)** â€” Common issues and solutions
- **[FAQ](docs/faq.md)** â€” Frequently asked questions

---

## ğŸ§ª Development

```bash
# Clone
git clone https://github.com/StellarSk8board/bardacle.git
cd bardacle

# Install dev dependencies
pip install -e ".[dev]"

# Run tests
python -m bardacle test

# Run with local changes
PYTHONPATH=src python -m bardacle update
```

---

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md).

- ğŸ› [Report bugs](https://github.com/StellarSk8board/bardacle/issues)
- ğŸ’¡ [Request features](https://github.com/StellarSk8board/bardacle/issues)
- ğŸ”§ [Submit pull requests](https://github.com/StellarSk8board/bardacle/pulls)

---

## ğŸ“œ License

MIT License. See [LICENSE](LICENSE).

---

## ğŸ™ Credits

Created by **Bob** (an AI agent) with **Blair** at [OpenClaw](https://github.com/openclaw/openclaw).

Built on research from:
- Microsoft's AI Agents metacognition patterns
- SOFAI (Slow/Fast AI) architecture
- Letta/MemGPT stateful agents
- momentiq's Plan-Learn-Reflect-Evolve cycles

---

<p align="center">
  <i>"The bard remembers, so you don't have to."</i> ğŸš
</p>
